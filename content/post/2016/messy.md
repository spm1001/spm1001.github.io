---
title: "Notes on Tim Hartford's 'Messy'"
date: "2016-12-23"
--- 

# Tim Hartford - Messy

## Do it in parallel
Scientists who produced strings of breakthrough papers kept changing the subject. 

3Ms 'flexible attention' policy means going to do something else - playing a game, taking a nap, going for a walk. All very James Webb Young. 

Benefits of multiple projects:
- Freshness and attention
- Unconscious processing
- Relief of frustration

## Teamwork

Optimal approach is neither isolated powerhouse tidy team nor a distributed network of far flung collaborators, but the combination - a network of teams...

> where two or three tightly bonded teams with very different creative histories had to find a way to work together over an extended period to produce something quite new.

> The logic behind these results is that when dealing with a complicated problem even the smartest person can get stuck. Adding a new perspective or a new set of skills can unstick us, even if the perspective is off-the-wall or the skills are mediocre. The fresh input works much like the Oblique Strategies employed by Brian Eno or the random leaps used by silicon chip algorithms. It’s the difference itself that helps.

> The problem comes when we ask a different question –not how well the group did, but how well the members of the group thought they’d done. The answers are remarkable. Members of diverse teams didn’t feel very sure that they’d got the right answer and they felt socially uncomfortable. The teams made up of four friends had a more pleasant time and they also tended to be confident –wrongly –that they had found the right answer.

People tend to prefer cohesion and consensus so if you want a high performing team err on the side of dissent. Fight homophily.  Seek out disagreement and discomfort. 

Then foster multiple insiders - people who are in the overlap of different groups. It is hard on them but better overall. Each coherent unit regards them as ‘one of us’ but they are also ‘one of them’

Focus more on ‘goal harmony’ than team harmony. Get everyone aligned on the task/brief but dissenting on the means. 

## The Habit of Yes - Improvisation

1. Practice until it becomes automatic
2. Be open to improv
3. Listen well for cues and clues

## Target Setting

Multiple unintended consequences of single targets. And the response of more sophisticated target setting may be counterproductive. (Cf Basel I and Basel II)

And even when you can have a sophisticated decision tree better to prune it to the key forks. Better uptake. 

Overfitting of a model is the equivalent of an overdose of hindsight. Paying too much attention to the minutiae and failing to learn what might matter in the future. 

In the target setting case a good option might be unpredictable tests chosen from a large variety of metrics. That way you can't game the system. And while you're at it why not randomise the timing of the test as well as the measures?

> ‘It’s a rather messier approach to supervision,’ admits Andy Haldane of his alternative vision. ‘But it can be done on an administrative shoestring. You wouldn’t need a large army. You’d need a small SWAT team.’ The mobility and unpredictability of the SWAT team is what many regulators desperately need.

## Paradox of automation. 

> The paradox of automation, then, has three strands to it. First, automatic systems accommodate incompetence by being easy to operate and by automatically correcting mistakes. Because of this an inexpert operator can function for a long time before his lack of skill becomes apparent –his incompetence is a hidden weakness that can persist almost indefinitely without being detected. Second, even if operators are expert, automatic systems erode their skills by removing the need for them to practise. Third, automatic systems tend to fail either in unusual situations or in ways that produce unusual situations, requiring a particularly skilful human response. For each of these three strands, a more capable and reliable automatic system makes the situation worse.

Points to the importance of expressing simple learnings in human form alongside ML techniques. Helps navigate failures. 

What is the equivalent of a flash crash in programmatic?

What are the tasks for humans in an algorithmic world? How can we manage the man-machine relationship better?

- be even more skilled to deal with the more complex failure modes
- generate sources of randomness for walking around
- make sure they understand and check ’common sense’, in extremis developing test cases and suites to validate behaviour
- maybe flip the polarity and have the machine supervise the human rather than the other way round?
- Create episodes of confusion to force humans to pay attention (cf Monderman's Squareabout)


> Crazy as this might seem, there’s a long tradition of using courageous questions to get us out of our tidy conversational habits. One list of questions was made famous by the novelist Marcel Proust, including ‘What is your most treasured possession?’; ‘What is the trait you most deplore in yourself?’; ‘What is your favourite journey?’; and ‘How would you like to die?’ All of these questions beat ‘What do you do for a living?’

## How to live a productively messy life
Work across different domains to stay fresh
Seek dissent to improve ideas
Ask off-beam questions 
Unfile

Seek dissent
Spin plates
Unfile


